{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "48c152da",
      "metadata": {},
      "source": [
        "# Data Exploration and Quality Assessment\n",
        "\n",
        "This notebook loads and explores the labels and transactions CSV files, documenting any data quality issues found including:\n",
        "- Missing values (nulls)\n",
        "- Duplicate records\n",
        "- Outliers\n",
        "- Data type issues\n",
        "- Referential integrity issues\n",
        "\n",
        "## Assumptions:\n",
        "1. Transaction amounts are in the same currency (no currency column present)\n",
        "2. Timestamps are in ISO 8601 format (YYYY-MM-DDTHH:MM:SS)\n",
        "3. Transaction types should be either 'credit' or 'debit'\n",
        "4. Default labels should be binary (0 or 1)\n",
        "5. Customer IDs should be consistent across both files\n",
        "6. Transaction IDs should be unique\n",
        "7. Amounts for credits should be positive, debits should be negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff651f89",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9991b653",
      "metadata": {},
      "source": [
        "## LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "86cef446",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LOADING DATA\n",
            "================================================================================\n",
            "\n",
            "Loading labels.csv...\n",
            "Labels shape: (5, 2)\n",
            "\n",
            "Loading transactions.csv...\n",
            "Transactions shape: (10, 6)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load labels CSV\n",
        "print(\"\\nLoading labels.csv...\")\n",
        "labels_df = pd.read_csv(\"data/labels.csv\")\n",
        "print(f\"Labels shape: {labels_df.shape}\")\n",
        "\n",
        "# Load transactions CSV\n",
        "print(\"\\nLoading transactions.csv...\")\n",
        "transactions_df = pd.read_csv(\"data/transactions.csv\")\n",
        "print(f\"Transactions shape: {transactions_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2b815e",
      "metadata": {},
      "source": [
        "## BASIC DATA EXPLORATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "94b83145",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- LABELS DATA ---\n",
            "\n",
            "First 3 rows:\n",
            "  customer_id  defaulted_within_90d\n",
            "0   CUST_0001                     0\n",
            "1   CUST_0002                     1\n",
            "2   CUST_0003                     0\n",
            "\n",
            "Data types:\n",
            "customer_id             object\n",
            "defaulted_within_90d     int64\n",
            "dtype: object\n",
            "\n",
            "Column names:\n",
            "['customer_id', 'defaulted_within_90d']\n",
            "\n",
            "Basic statistics:\n",
            "       customer_id  defaulted_within_90d\n",
            "count            5              5.000000\n",
            "unique           5                   NaN\n",
            "top      CUST_0001                   NaN\n",
            "freq             1                   NaN\n",
            "mean           NaN              0.400000\n",
            "std            NaN              0.547723\n",
            "min            NaN              0.000000\n",
            "25%            NaN              0.000000\n",
            "50%            NaN              0.000000\n",
            "75%            NaN              1.000000\n",
            "max            NaN              1.000000\n"
          ]
        }
      ],
      "source": [
        "# Labels exploration\n",
        "print(\"--- LABELS DATA ---\")\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "print(labels_df.head(3))\n",
        "print(\"\\nData types:\")\n",
        "print(labels_df.dtypes)\n",
        "print(\"\\nColumn names:\")\n",
        "print(labels_df.columns.tolist())\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(labels_df.describe(include=\"all\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2fb4de82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- TRANSACTIONS DATA ---\n",
            "\n",
            "First 3 rows:\n",
            "  transaction_id customer_id        txn_timestamp   amount txn_type  \\\n",
            "0         T00001   CUST_0001  2025-02-01T10:05:00  2500.00   credit   \n",
            "1         T00002   CUST_0001  2025-02-02T12:15:00   -45.99    debit   \n",
            "2         T00003   CUST_0001  2025-02-04T08:05:00   -19.99    debit   \n",
            "\n",
            "            description  \n",
            "0  ACME LTD PAYROLL FEB  \n",
            "1     TESCO 1234 LONDON  \n",
            "2           NETFLIX.COM  \n",
            "\n",
            "Data types:\n",
            "transaction_id     object\n",
            "customer_id        object\n",
            "txn_timestamp      object\n",
            "amount            float64\n",
            "txn_type           object\n",
            "description        object\n",
            "dtype: object\n",
            "\n",
            "Column names:\n",
            "['transaction_id', 'customer_id', 'txn_timestamp', 'amount', 'txn_type', 'description']\n",
            "\n",
            "Basic statistics:\n",
            "       transaction_id customer_id        txn_timestamp       amount txn_type  \\\n",
            "count              10          10                   10    10.000000       10   \n",
            "unique             10           5                   10          NaN        2   \n",
            "top            T00001   CUST_0001  2025-02-01T10:05:00          NaN   credit   \n",
            "freq                1           3                    1          NaN        5   \n",
            "mean              NaN         NaN                  NaN  1148.402000      NaN   \n",
            "std               NaN         NaN                  NaN  2146.748009      NaN   \n",
            "min               NaN         NaN                  NaN  -650.000000      NaN   \n",
            "25%               NaN         NaN                  NaN  -236.497500      NaN   \n",
            "50%               NaN         NaN                  NaN   440.005000      NaN   \n",
            "75%               NaN         NaN                  NaN  1650.000000      NaN   \n",
            "max               NaN         NaN                  NaN  6500.000000      NaN   \n",
            "\n",
            "                 description  \n",
            "count                     10  \n",
            "unique                     7  \n",
            "top     ACME LTD PAYROLL FEB  \n",
            "freq                       3  \n",
            "mean                     NaN  \n",
            "std                      NaN  \n",
            "min                      NaN  \n",
            "25%                      NaN  \n",
            "50%                      NaN  \n",
            "75%                      NaN  \n",
            "max                      NaN  \n"
          ]
        }
      ],
      "source": [
        "# Transactions exploration\n",
        "print(\"--- TRANSACTIONS DATA ---\")\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "print(transactions_df.head(3))\n",
        "print(\"\\nData types:\")\n",
        "print(transactions_df.dtypes)\n",
        "print(\"\\nColumn names:\")\n",
        "print(transactions_df.columns.tolist())\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(transactions_df.describe(include=\"all\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea484f4",
      "metadata": {},
      "source": [
        "## DATA QUALITY ASSESSMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b8dca12c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_quality_issues = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc44a2bf",
      "metadata": {},
      "source": [
        "### 1. MISSING VALUES CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "53cec1e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ No missing values in labels.csv\n",
            "\n",
            "✅ No missing values in transactions.csv\n"
          ]
        }
      ],
      "source": [
        "# Check labels for nulls\n",
        "labels_nulls = labels_df.isnull().sum()\n",
        "if labels_nulls.sum() > 0:\n",
        "    print(\"❌ NULLS FOUND IN LABELS:\")\n",
        "    print(labels_nulls[labels_nulls > 0])\n",
        "    data_quality_issues.append({\"file\": \"labels.csv\", \"issue\": \"Missing values\", \"details\": labels_nulls[labels_nulls > 0].to_dict()})\n",
        "else:\n",
        "    print(\"✅ No missing values in labels.csv\")\n",
        "\n",
        "# Check transactions for nulls\n",
        "transactions_nulls = transactions_df.isnull().sum()\n",
        "if transactions_nulls.sum() > 0:\n",
        "    print(\"\\n❌ NULLS FOUND IN TRANSACTIONS:\")\n",
        "    print(transactions_nulls[transactions_nulls > 0])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Missing values\", \"details\": transactions_nulls[transactions_nulls > 0].to_dict()})\n",
        "else:\n",
        "    print(\"\\n✅ No missing values in transactions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074d4894",
      "metadata": {},
      "source": [
        "### 2. DUPLICATE RECORDS CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8051612b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ No duplicate rows in labels.csv\n",
            "\n",
            "✅ All customer_ids are unique in labels.csv\n",
            "\n",
            "✅ No duplicate rows in transactions.csv\n",
            "\n",
            "✅ All transaction_ids are unique in transactions.csv\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate rows in labels\n",
        "labels_duplicates = labels_df.duplicated().sum()\n",
        "if labels_duplicates > 0:\n",
        "    print(f\"❌ Found {labels_duplicates} duplicate rows in labels.csv\")\n",
        "    data_quality_issues.append({\"file\": \"labels.csv\", \"issue\": \"Duplicate rows\", \"count\": labels_duplicates})\n",
        "else:\n",
        "    print(\"✅ No duplicate rows in labels.csv\")\n",
        "\n",
        "# Check for duplicate customer_ids in labels (should be unique)\n",
        "labels_dup_customers = labels_df[\"customer_id\"].duplicated().sum()\n",
        "if labels_dup_customers > 0:\n",
        "    print(f\"\\n❌ Found {labels_dup_customers} duplicate customer_ids in labels.csv\")\n",
        "    print(\"Duplicate customer_ids:\")\n",
        "    print(labels_df[labels_df[\"customer_id\"].duplicated(keep=False)])\n",
        "    data_quality_issues.append({\"file\": \"labels.csv\", \"issue\": \"Duplicate customer_ids\", \"count\": labels_dup_customers})\n",
        "else:\n",
        "    print(\"\\n✅ All customer_ids are unique in labels.csv\")\n",
        "\n",
        "# Check for duplicate rows in transactions\n",
        "transactions_duplicates = transactions_df.duplicated().sum()\n",
        "if transactions_duplicates > 0:\n",
        "    print(f\"\\n❌ Found {transactions_duplicates} duplicate rows in transactions.csv\")\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Duplicate rows\", \"count\": transactions_duplicates})\n",
        "else:\n",
        "    print(\"\\n✅ No duplicate rows in transactions.csv\")\n",
        "\n",
        "# Check for duplicate transaction_ids (should be unique)\n",
        "transactions_dup_ids = transactions_df[\"transaction_id\"].duplicated().sum()\n",
        "if transactions_dup_ids > 0:\n",
        "    print(f\"\\n❌ Found {transactions_dup_ids} duplicate transaction_ids in transactions.csv\")\n",
        "    print(\"Duplicate transaction_ids:\")\n",
        "    print(transactions_df[transactions_df[\"transaction_id\"].duplicated(keep=False)])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Duplicate transaction_ids\", \"count\": transactions_dup_ids})\n",
        "else:\n",
        "    print(\"\\n✅ All transaction_ids are unique in transactions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb7d164",
      "metadata": {},
      "source": [
        "### 3. DATA TYPE VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a467609c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Transaction timestamps are valid datetime format\n",
            "\n",
            "✅ All defaulted_within_90d values are valid (0 or 1)\n",
            "\n",
            "✅ All transaction types are valid ('credit' or 'debit')\n",
            "\n",
            "✅ Amount column is numeric\n"
          ]
        }
      ],
      "source": [
        "# Convert txn_timestamp to datetime for validation\n",
        "try:\n",
        "    transactions_df[\"txn_timestamp\"] = pd.to_datetime(transactions_df[\"txn_timestamp\"])\n",
        "    print(\"✅ Transaction timestamps are valid datetime format\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR converting timestamps: {e}\")\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Invalid timestamp format\", \"details\": str(e)})\n",
        "\n",
        "# Check defaulted_within_90d values (should be 0 or 1)\n",
        "invalid_defaults = labels_df[~labels_df[\"defaulted_within_90d\"].isin([0, 1])]\n",
        "if len(invalid_defaults) > 0:\n",
        "    print(f\"\\n❌ Found {len(invalid_defaults)} invalid defaulted_within_90d values (should be 0 or 1):\")\n",
        "    print(invalid_defaults)\n",
        "    data_quality_issues.append({\"file\": \"labels.csv\", \"issue\": \"Invalid defaulted_within_90d values\", \"count\": len(invalid_defaults)})\n",
        "else:\n",
        "    print(\"\\n✅ All defaulted_within_90d values are valid (0 or 1)\")\n",
        "\n",
        "# Check transaction types (should be 'credit' or 'debit')\n",
        "invalid_txn_types = transactions_df[~transactions_df[\"txn_type\"].isin([\"credit\", \"debit\"])]\n",
        "if len(invalid_txn_types) > 0:\n",
        "    print(f\"\\n❌ Found {len(invalid_txn_types)} invalid transaction types:\")\n",
        "    print(invalid_txn_types)\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Invalid transaction types\", \"count\": len(invalid_txn_types)})\n",
        "else:\n",
        "    print(\"\\n✅ All transaction types are valid ('credit' or 'debit')\")\n",
        "\n",
        "# Check amount data type\n",
        "if not pd.api.types.is_numeric_dtype(transactions_df[\"amount\"]):\n",
        "    print(\"\\n❌ Amount column is not numeric\")\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Amount column not numeric\"})\n",
        "else:\n",
        "    print(\"\\n✅ Amount column is numeric\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f70e77a",
      "metadata": {},
      "source": [
        "### 4. OUTLIER DETECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ad20d09a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for extremely large or small amounts\n",
        "# Assumption: Amounts should be reasonable (e.g., between -1,000,000 and 1,000,000)\n",
        "# This is a business rule assumption\n",
        "EXTREME_THRESHOLD = 1000000\n",
        "extreme_amounts = transactions_df[abs(transactions_df[\"amount\"]) > EXTREME_THRESHOLD]\n",
        "if len(extreme_amounts) > 0:\n",
        "    print(f\"\\n⚠️  Found {len(extreme_amounts)} transactions with extremely large amounts (> {EXTREME_THRESHOLD:,}):\")\n",
        "    print(extreme_amounts[[\"transaction_id\", \"customer_id\", \"amount\", \"txn_type\", \"description\"]])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Extremely large amounts\", \"count\": len(extreme_amounts), \"threshold\": EXTREME_THRESHOLD})\n",
        "\n",
        "# Check for zero amounts\n",
        "zero_amounts = transactions_df[transactions_df[\"amount\"] == 0]\n",
        "if len(zero_amounts) > 0:\n",
        "    print(f\"\\n⚠️  Found {len(zero_amounts)} transactions with zero amount:\")\n",
        "    print(zero_amounts[[\"transaction_id\", \"customer_id\", \"amount\", \"txn_type\", \"description\"]])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Zero amount transactions\", \"count\": len(zero_amounts)})\n",
        "\n",
        "# Check timestamp outliers (future dates or very old dates)\n",
        "# Assumption: Transactions should be between 2000-01-01 and current date + 1 year\n",
        "if \"txn_timestamp\" in transactions_df.columns and pd.api.types.is_datetime64_any_dtype(transactions_df[\"txn_timestamp\"]):\n",
        "    min_reasonable_date = pd.Timestamp(\"2000-01-01\")\n",
        "    max_reasonable_date = pd.Timestamp.now() + pd.Timedelta(days=365)\n",
        "\n",
        "    future_dates = transactions_df[transactions_df[\"txn_timestamp\"] > max_reasonable_date]\n",
        "    old_dates = transactions_df[transactions_df[\"txn_timestamp\"] < min_reasonable_date]\n",
        "\n",
        "    if len(future_dates) > 0:\n",
        "        print(f\"\\n⚠️  Found {len(future_dates)} transactions with future dates:\")\n",
        "        print(future_dates[[\"transaction_id\", \"customer_id\", \"txn_timestamp\", \"amount\"]])\n",
        "        data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Future date transactions\", \"count\": len(future_dates)})\n",
        "\n",
        "    if len(old_dates) > 0:\n",
        "        print(f\"\\n⚠️  Found {len(old_dates)} transactions with very old dates (< 2000-01-01):\")\n",
        "        print(old_dates[[\"transaction_id\", \"customer_id\", \"txn_timestamp\", \"amount\"]])\n",
        "        data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Very old date transactions\", \"count\": len(old_dates)})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c807bfe",
      "metadata": {},
      "source": [
        "### 5. BUSINESS LOGIC VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b512e2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Transaction types and amounts are consistent (credits positive, debits negative)\n"
          ]
        }
      ],
      "source": [
        "# Check if credit transactions have positive amounts and debit transactions have negative amounts\n",
        "# Assumption: Credits should be positive, debits should be negative\n",
        "credit_negative = transactions_df[(transactions_df[\"txn_type\"] == \"credit\") & (transactions_df[\"amount\"] < 0)]\n",
        "debit_positive = transactions_df[(transactions_df[\"txn_type\"] == \"debit\") & (transactions_df[\"amount\"] > 0)]\n",
        "\n",
        "if len(credit_negative) > 0:\n",
        "    print(f\"⚠️  Found {len(credit_negative)} credit transactions with negative amounts:\")\n",
        "    print(credit_negative[[\"transaction_id\", \"customer_id\", \"amount\", \"txn_type\"]])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Credit transactions with negative amounts\", \"count\": len(credit_negative)})\n",
        "\n",
        "if len(debit_positive) > 0:\n",
        "    print(f\"\\n⚠️  Found {len(debit_positive)} debit transactions with positive amounts:\")\n",
        "    print(debit_positive[[\"transaction_id\", \"customer_id\", \"amount\", \"txn_type\"]])\n",
        "    data_quality_issues.append({\"file\": \"transactions.csv\", \"issue\": \"Debit transactions with positive amounts\", \"count\": len(debit_positive)})\n",
        "\n",
        "if len(credit_negative) == 0 and len(debit_positive) == 0:\n",
        "    print(\"✅ Transaction types and amounts are consistent (credits positive, debits negative)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7296a7b0",
      "metadata": {},
      "source": [
        "### 6. REFERENTIAL INTEGRITY CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7f42eae8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All customer_ids in transactions exist in labels\n",
            "\n",
            "✅ All customer_ids in labels have at least one transaction\n"
          ]
        }
      ],
      "source": [
        "# Check if all customer_ids in transactions exist in labels\n",
        "unique_labels_customers = set(labels_df[\"customer_id\"].unique())\n",
        "unique_transactions_customers = set(transactions_df[\"customer_id\"].unique())\n",
        "\n",
        "missing_in_labels = unique_transactions_customers - unique_labels_customers\n",
        "if len(missing_in_labels) > 0:\n",
        "    print(f\"❌ Found {len(missing_in_labels)} customer_ids in transactions that don't exist in labels:\")\n",
        "    print(list(missing_in_labels))\n",
        "    data_quality_issues.append(\n",
        "        {\"file\": \"transactions.csv\", \"issue\": \"Customer IDs missing in labels\", \"count\": len(missing_in_labels), \"customer_ids\": list(missing_in_labels)}\n",
        "    )\n",
        "else:\n",
        "    print(\"✅ All customer_ids in transactions exist in labels\")\n",
        "\n",
        "# Check if all customer_ids in labels have transactions\n",
        "missing_in_transactions = unique_labels_customers - unique_transactions_customers\n",
        "if len(missing_in_transactions) > 0:\n",
        "    print(f\"\\n⚠️  Found {len(missing_in_transactions)} customer_ids in labels with no transactions:\")\n",
        "    print(list(missing_in_transactions))\n",
        "    data_quality_issues.append(\n",
        "        {\"file\": \"labels.csv\", \"issue\": \"Customer IDs with no transactions\", \"count\": len(missing_in_transactions), \"customer_ids\": list(missing_in_transactions)}\n",
        "    )\n",
        "else:\n",
        "    print(\"\\n✅ All customer_ids in labels have at least one transaction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51445be",
      "metadata": {},
      "source": [
        "## SUMMARY STATISTICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6fd0dfe2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- LABELS SUMMARY ---\n",
            "Total customers: 5\n",
            "Customers with default (1): 2\n",
            "Customers without default (0): 3\n",
            "Default rate: 40.00%\n",
            "\n",
            "--- TRANSACTIONS SUMMARY ---\n",
            "Total transactions: 10\n",
            "Credit transactions: 5\n",
            "Debit transactions: 5\n",
            "Total credit amount: 12,900.00\n",
            "Total debit amount: -1,415.98\n",
            "Net amount: 11,484.02\n",
            "\n",
            "Date range:\n",
            "  Earliest transaction: 2025-02-01 06:30:00\n",
            "  Latest transaction: 2025-02-04 08:05:00\n",
            "  Date span: 3 days\n",
            "\n",
            "Amount statistics:\n",
            "  Min amount: -650.00\n",
            "  Max amount: 6,500.00\n",
            "  Mean amount: 1,148.40\n",
            "  Median amount: 440.00\n",
            "  Std deviation: 2,146.75\n",
            "\n",
            "Transactions per customer:\n",
            "  Min: 1\n",
            "  Max: 3\n",
            "  Mean: 2.00\n",
            "  Median: 2.00\n"
          ]
        }
      ],
      "source": [
        "print(\"--- LABELS SUMMARY ---\")\n",
        "print(f\"Total customers: {len(labels_df)}\")\n",
        "print(f\"Customers with default (1): {labels_df['defaulted_within_90d'].sum()}\")\n",
        "print(f\"Customers without default (0): {(labels_df['defaulted_within_90d'] == 0).sum()}\")\n",
        "print(f\"Default rate: {labels_df['defaulted_within_90d'].mean():.2%}\")\n",
        "\n",
        "print(\"\\n--- TRANSACTIONS SUMMARY ---\")\n",
        "print(f\"Total transactions: {len(transactions_df)}\")\n",
        "print(f\"Credit transactions: {(transactions_df['txn_type'] == 'credit').sum()}\")\n",
        "print(f\"Debit transactions: {(transactions_df['txn_type'] == 'debit').sum()}\")\n",
        "print(f\"Total credit amount: {transactions_df[transactions_df['txn_type'] == 'credit']['amount'].sum():,.2f}\")\n",
        "print(f\"Total debit amount: {transactions_df[transactions_df['txn_type'] == 'debit']['amount'].sum():,.2f}\")\n",
        "print(f\"Net amount: {transactions_df['amount'].sum():,.2f}\")\n",
        "\n",
        "if \"txn_timestamp\" in transactions_df.columns and pd.api.types.is_datetime64_any_dtype(transactions_df[\"txn_timestamp\"]):\n",
        "    print(f\"\\nDate range:\")\n",
        "    print(f\"  Earliest transaction: {transactions_df['txn_timestamp'].min()}\")\n",
        "    print(f\"  Latest transaction: {transactions_df['txn_timestamp'].max()}\")\n",
        "    print(f\"  Date span: {(transactions_df['txn_timestamp'].max() - transactions_df['txn_timestamp'].min()).days} days\")\n",
        "\n",
        "print(f\"\\nAmount statistics:\")\n",
        "print(f\"  Min amount: {transactions_df['amount'].min():,.2f}\")\n",
        "print(f\"  Max amount: {transactions_df['amount'].max():,.2f}\")\n",
        "print(f\"  Mean amount: {transactions_df['amount'].mean():,.2f}\")\n",
        "print(f\"  Median amount: {transactions_df['amount'].median():,.2f}\")\n",
        "print(f\"  Std deviation: {transactions_df['amount'].std():,.2f}\")\n",
        "\n",
        "# Transactions per customer\n",
        "transactions_per_customer = transactions_df.groupby(\"customer_id\").size()\n",
        "print(f\"\\nTransactions per customer:\")\n",
        "print(f\"  Min: {transactions_per_customer.min()}\")\n",
        "print(f\"  Max: {transactions_per_customer.max()}\")\n",
        "print(f\"  Mean: {transactions_per_customer.mean():.2f}\")\n",
        "print(f\"  Median: {transactions_per_customer.median():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd8ef57",
      "metadata": {},
      "source": [
        "## DATA QUALITY ISSUES SUMMARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0537b669",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ No data quality issues found!\n"
          ]
        }
      ],
      "source": [
        "if len(data_quality_issues) == 0:\n",
        "    print(\"✅ No data quality issues found!\")\n",
        "else:\n",
        "    print(f\"⚠️  Found {len(data_quality_issues)} data quality issue(s):\\n\")\n",
        "    for i, issue in enumerate(data_quality_issues, 1):\n",
        "        print(f\"{i}. File: {issue['file']}\")\n",
        "        print(f\"   Issue: {issue['issue']}\")\n",
        "        if \"count\" in issue:\n",
        "            print(f\"   Count: {issue['count']}\")\n",
        "        if \"details\" in issue:\n",
        "            print(f\"   Details: {issue['details']}\")\n",
        "        if \"customer_ids\" in issue:\n",
        "            print(f\"   Customer IDs: {issue['customer_ids']}\")\n",
        "        print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
